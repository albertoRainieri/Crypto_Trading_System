{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cc15fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRODUCTION ENVIRONMENT\n",
      "Script started at:  2023-06-29 12:20:48.672591+00:00\n",
      "StatusCode for getting most_traded_coins: 200\n",
      "new Json saved in /home/alberto/Docker/Trading/tracker/json/most_traded_coins.json\n",
      "Most recent file is /home/alberto/Docker/Trading/analysis/json/data-27-06-2023-04-18.json\n",
      "This is the path_json variable: /home/alberto/Docker/Trading/analysis/json/data-27-06-2023-04-18.json\n",
      "2023-06-29T12:20:51 Making the request to https://algocrypto.eu/analysis/get-data/\n",
      "Starting to query from: 2023-06-28 00:00:12\n",
      "Iterationg through new data is completed.\n",
      "No New Instrument was fetched from the request\n",
      "0 new observations for 206 coins\n",
      "new Json saved in /home/alberto/Docker/Trading/analysis/json/data-27-06-2023-04-18.json\n",
      "\n",
      "2023-06-29T12:21:52 Making the request to https://algocrypto.eu/analysis/get-data/\n",
      "Starting to query from: 2023-06-28 06:00:12\n",
      "Iterationg through new data is completed.\n",
      "No New Instrument was fetched from the request\n",
      "0 new observations for 28 coins\n",
      "new Json saved in /home/alberto/Docker/Trading/analysis/json/data-27-06-2023-04-18.json\n",
      "\n",
      "2023-06-29T12:22:22 Making the request to https://algocrypto.eu/analysis/get-data/\n",
      "Starting to query from: 2023-06-28 12:00:12\n",
      "Iterationg through new data is completed.\n",
      "No New Instrument was fetched from the request\n",
      "0 new observations for 28 coins\n",
      "new Json saved in /home/alberto/Docker/Trading/analysis/json/data-27-06-2023-04-18.json\n",
      "\n",
      "2023-06-29T12:23:02 Making the request to https://algocrypto.eu/analysis/get-data/\n",
      "Starting to query from: 2023-06-28 18:00:12\n",
      "Iterationg through new data is completed.\n",
      "No New Instrument was fetched from the request\n",
      "0 new observations for 206 coins\n",
      "new Json saved in /home/alberto/Docker/Trading/analysis/json/data-27-06-2023-04-18.json\n",
      "\n",
      "2023-06-29T12:23:42 Making the request to https://algocrypto.eu/analysis/get-data/\n",
      "Starting to query from: 2023-06-29 00:00:12\n",
      "Iterationg through new data is completed.\n",
      "No New Instrument was fetched from the request\n",
      "0 new observations for 28 coins\n",
      "new Json saved in /home/alberto/Docker/Trading/analysis/json/data-27-06-2023-04-18.json\n",
      "\n",
      "2023-06-29T12:24:23 Making the request to https://algocrypto.eu/analysis/get-data/\n",
      "Starting to query from: 2023-06-29 06:00:12\n",
      "Iterationg through new data is completed.\n",
      "No New Instrument was fetched from the request\n",
      "0 new observations for 28 coins\n",
      "new Json saved in /home/alberto/Docker/Trading/analysis/json/data-27-06-2023-04-18.json\n",
      "\n",
      "2023-06-29T12:25:02 Making the request to https://algocrypto.eu/analysis/get-data/\n",
      "Starting to query from: 2023-06-29 12:00:12\n",
      "Iterationg through new data is completed.\n",
      "No New Instrument was fetched from the request\n",
      "0 new observations for 28 coins\n",
      "new Json saved in /home/alberto/Docker/Trading/analysis/json/data-27-06-2023-04-18.json\n",
      "\n",
      "Time Spent: 290.1521546840668 \n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timezone, timedelta, date\n",
    "import os\n",
    "from time import time\n",
    "from backend.constants.constants import ACCESS_TOKEN\n",
    "from time import sleep\n",
    "import pytz\n",
    "\n",
    "\n",
    "PRODUCTION = True\n",
    "t1 = time()\n",
    "\n",
    "if PRODUCTION:\n",
    "    print('PRODUCTION ENVIRONMENT')\n",
    "    ENDPOINT = 'https://algocrypto.eu'\n",
    "    DAYS=0.25\n",
    "    path_dir = '/home/alberto/Docker/Trading/analysis/json'\n",
    "else:\n",
    "    print('DEVELOPMENT ENVIRONMENT')\n",
    "    path_dir = '/home/alberto/Docker/Trading/analysis/json_test'\n",
    "    ENDPOINT = 'http://localhost'\n",
    "    DAYS=0.4\n",
    "    \n",
    "    \n",
    "new_datetime_start = datetime.now(timezone.utc)\n",
    "print('Script started at: ', new_datetime_start)\n",
    "\n",
    "method = '/analysis/get-data/'\n",
    "method_most_traded_coins = '/analysis/get-mosttradedcoins'\n",
    "datetime_start = datetime(2023,5,7)\n",
    "datetime_start = pytz.utc.localize(datetime_start)\n",
    "year_now = str(datetime.now().year)\n",
    "month_now = str(datetime.now().month)\n",
    "day_now = str(datetime.now().day)\n",
    "\n",
    "datetime_start_iso = datetime_start.isoformat()\n",
    "\n",
    "\n",
    "headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {ACCESS_TOKEN}\", \n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "# get MOST_TRADED_COINS.json froms server\n",
    "url_mosttradedcoins = ENDPOINT + method_most_traded_coins\n",
    "response = requests.get(url_mosttradedcoins)\n",
    "print(f'StatusCode for getting most_traded_coins: {response.status_code}')\n",
    "most_traded_coins = response.json()\n",
    "path_json_mostradedcoins = \"/home/alberto/Docker/Trading/tracker/json/most_traded_coins.json\"\n",
    "\n",
    "# save MOST_TRADED_COINS.json\n",
    "with open(path_json_mostradedcoins, 'w') as outfile:\n",
    "    outfile.write(most_traded_coins)\n",
    "    print(f'new Json saved in {path_json_mostradedcoins}')\n",
    "\n",
    "# START GATHERING ALL TRACKER DATA\n",
    "\n",
    "list_json = os.listdir(path_dir)\n",
    "# if data.json already exists, get saved data\n",
    "if len(list_json) != 0:\n",
    "    \n",
    "    # get all full paths in json directory\n",
    "    full_paths = [path_dir + \"/{0}\".format(x) for x in list_json]\n",
    "\n",
    "    #print(full_path)\n",
    "    most_recent_datetime = datetime(2020,1,1)\n",
    "    # get the most recent json\n",
    "    for full_path in full_paths:\n",
    "        file_name = full_path.split('/')[-1]\n",
    "        file_name_split = file_name.split('-')\n",
    "        day = int(file_name_split[1])\n",
    "        month = int(file_name_split[2])\n",
    "        year = int(file_name_split[3])\n",
    "        \n",
    "        datetime_file_path = datetime(year=year, month=month, day=day)\n",
    "\n",
    "        if datetime_file_path > most_recent_datetime:\n",
    "            most_recent_datetime = datetime_file_path\n",
    "            most_recent_file = full_path\n",
    "\n",
    "    #most_recent_file = max(full_path, key=os.path.getctime)\n",
    "    print(f'Most recent file is {most_recent_file}')\n",
    "\n",
    "    # get datetime from name json file\n",
    "    f = open (most_recent_file, \"r\")\n",
    "    data = json.loads(f.read())\n",
    "    datetime_start_iso = data['datetime_creation']\n",
    "    path_json = most_recent_file\n",
    "\n",
    "    datetime_start = datetime.fromisoformat(datetime_start_iso)\n",
    "    datetime_end_iso = (datetime_start + timedelta(days=DAYS)).isoformat()\n",
    "    \n",
    "#if data.json does not exists, initialize data variable\n",
    "else:\n",
    "    t = datetime.now()\n",
    "    year = str(t.year)\n",
    "    month = str(t.month)\n",
    "    day = str(t.day)\n",
    "    second = str(t.second)\n",
    "    minute = str(t.minute)\n",
    "    hour = str(t.hour)\n",
    "    path_json = f'{path_dir}/data-{day}-{month}-{year}-{hour}{minute}{second}.json'\n",
    "    date_split = datetime_start_iso.split('T')\n",
    "    date = date_split[0]\n",
    "    hour = date_split[1].split('.')[0]\n",
    "    datetime_end_iso = (datetime_start + timedelta(days=DAYS)).isoformat()\n",
    "    data = {'datetime_creation': datetime_start_iso, 'data': {}}\n",
    "    \n",
    "\n",
    "print(f'This is the path_json variable: {path_json}')\n",
    "\n",
    "# START RETRIEVING DATA FROM SERVER\n",
    "while (new_datetime_start - datetime_start).days >= 0:\n",
    "\n",
    "    while datetime.now().second < 0 and datetime.now().second > 10:\n",
    "        sleep(0.9)\n",
    "    \n",
    "    # GET DATETIME FOR LOGGING\n",
    "    days_timedelta_iteration = (new_datetime_start - datetime_start).days\n",
    "    date_split = datetime_start_iso.split('T')\n",
    "    date = date_split[0]\n",
    "    hour = date_split[1].split('.')[0]\n",
    "\n",
    "    \n",
    "    # PREPARE AND MAKE NEW REQUEST TO SERVER\n",
    "    params = {'datetime_start': datetime_start_iso, 'datetime_end': datetime_end_iso}\n",
    "    url = ENDPOINT + method\n",
    "    now_iso = datetime.now(timezone.utc).isoformat().split('.')[0]\n",
    "    print(f'{now_iso} Making the request to {url}')\n",
    "    print(f'Starting to query from: {date} {hour}')\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    #response = requests.get(url, params=params)\n",
    "    new_instrument_data=0\n",
    "    \n",
    "\n",
    "    # START UPDATING \"DATA\" (I.E. ADD ALL THE NEW OBSERVATIONS)\n",
    "    if response.status_code == 200:\n",
    "        new_data = response.json()\n",
    "        n_instrument_newdata = 0\n",
    "        n_observations = 0\n",
    "        # UPDATE DATA\n",
    "        for instrument_name in new_data:\n",
    "            if instrument_name in data['data']:\n",
    "                for trade in new_data[instrument_name]:\n",
    "                    data['data'][instrument_name].append(trade)\n",
    "            else:\n",
    "                print(f'new instrument_name: {instrument_name}')\n",
    "                new_instrument_data += 1\n",
    "                data['data'][instrument_name] = []\n",
    "                for trade in new_data[instrument_name]:\n",
    "                    data['data'][instrument_name].append(trade)\n",
    "\n",
    "        # UPDATE DATETIME_CREATION\n",
    "        if days_timedelta_iteration == 0:\n",
    "            datetime_creation = (datetime.fromisoformat(data['data']['BTCUSDT'][-1]['_id']) + timedelta(seconds=10))\n",
    "            datetime_creation = (pytz.utc.localize(datetime_creation)).isoformat()\n",
    "        else:\n",
    "            datetime_creation = datetime_end_iso\n",
    "        data['datetime_creation'] = datetime_creation\n",
    "        \n",
    "        # PRINT SOME INFO\n",
    "        print(f'Iterationg through new data is completed.')\n",
    "        if new_instrument_data != 0:\n",
    "            print(f'{new_instrument_data} of the instrument fetched are NEW')\n",
    "        else:\n",
    "            print(\"No New Instrument was fetched from the request\")\n",
    "        btc_obs = len(new_data['BTCUSDT'])\n",
    "        count_coins = sum([1 for coin in list(new_data.keys()) if len(new_data[coin]) != 0])\n",
    "        print(f'{btc_obs} new observations for {count_coins} coins')\n",
    "        \n",
    "        # if 'ASTUSDT' in data['data']:\n",
    "        #     del data['data']['ASTUSDT']\n",
    "        # if 'SNTUSDT' in data['data']:\n",
    "        #     del data['data']['SNTUSDT']    \n",
    "        \n",
    "\n",
    "        # SAVE UPDATED DATA TO PATH\n",
    "        json_string = json.dumps(data)\n",
    "        with open(path_json, 'w') as outfile:\n",
    "            outfile.write(json_string)\n",
    "        print(f'new Json saved in {path_json}')\n",
    "\n",
    "        # check size of file, if it is too great than reinitialize path_json and data\n",
    "        if os.path.getsize(path_json) > 1400000000:\n",
    "            last_record = data['data']['BTCUSDT'][-1]['_id']\n",
    "\n",
    "            last_record_split = last_record.split('-')\n",
    "            last_record_split2 = last_record.split(':')\n",
    "            year = last_record_split[0]\n",
    "            month = last_record_split[1]\n",
    "            day = last_record_split[2][:2]\n",
    "            hour = last_record_split2[0][-2:]\n",
    "            minute = str(int(last_record_split2[1]) + 1)\n",
    "            path_json = f'{path_dir}/data-{day}-{month}-{year}-{hour}-{minute}.json'\n",
    "            print(F'NEW JSON INITIALIZED WITH PATH {path_json}')\n",
    "            data = {'datetime_creation': datetime_start_iso, 'data': {}}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # UPDATE PARAMETERS FOR MAKING THE NEXT REQUEST\n",
    "        datetime_start = datetime_start + timedelta(days=DAYS)\n",
    "        datetime_end = datetime_start + timedelta(days=DAYS)\n",
    "        datetime_start_iso = datetime_start.isoformat()\n",
    "        datetime_end_iso = datetime_end.isoformat()\n",
    "        new_datetime_start = datetime.now(timezone.utc)\n",
    "        print('')\n",
    "        \n",
    "\n",
    "    else:\n",
    "        print('SOMETHING WRONG HAPPENED: ', response.status_code)\n",
    "        print()\n",
    "        break\n",
    "\n",
    "    \n",
    "t2 = time()\n",
    "t = t2-t1\n",
    "print(f'Time Spent: {t} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ec7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3910dfc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
